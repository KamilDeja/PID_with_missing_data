{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\Desktop\\research\\pdi\n"
     ]
    }
   ],
   "source": [
    "# switch to the project directory\n",
    "%cd ..\n",
    "# working directory should be ../pdi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "module_path = os.path.abspath('src')\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdi.constants import (\n",
    "    PARTICLES_DICT,\n",
    "    TARGET_CODES\n",
    ")\n",
    "from pdi.data.constants import GROUP_ID_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from pdi.data.preparation import FeatureSetPreparation\n",
    "from pdi.models import AttentionModel\n",
    "from pdi.data.types import Split\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import json\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "data_preparation = FeatureSetPreparation()\n",
    "(train_loader, ) = data_preparation.prepare_dataloaders(64, 0, [Split.TRAIN])\n",
    "\n",
    "it = iter(train_loader)\n",
    "dummy_input1, _, _ = next(it)\n",
    "dummy_input2, _, _ = next(it)\n",
    "\n",
    "dummy_input1.to(device)\n",
    "dummy_input2.to(device)\n",
    "\n",
    "thresholds = {}\n",
    "\n",
    "os.makedirs(f\"onnx/Proposed/\", exist_ok=True)\n",
    "for target_code in TARGET_CODES:\n",
    "    load_path = f\"models/Proposed/{PARTICLES_DICT[target_code]}.pt\"\n",
    "    export_path = f\"onnx/Proposed/{PARTICLES_DICT[target_code]}.onnx\"\n",
    "    saved_model = torch.load(load_path)\n",
    "    model = AttentionModel(*saved_model[\"model_args\"]).to(device)\n",
    "    model.eval()\n",
    "    model.thres = saved_model[\"model_thres\"]\n",
    "    model.load_state_dict(saved_model[\"state_dict\"])\n",
    "\n",
    "    thresholds[PARTICLES_DICT[target_code]] = float(model.thres)\n",
    "\n",
    "    torch.onnx.export(model, (dummy_input1, dummy_input2), export_path, input_names=[\"input\"], output_names=[\"output\"], \n",
    "        dynamic_axes={'input' : {0 : 'batch_size', 1 : 'feature_num'},    # variable length axes\n",
    "                      'output' : {0 : 'batch_size'}})\n",
    "\n",
    "    onnx_model = onnx.load(export_path)\n",
    "    onnx.checker.check_model(onnx_model)\n",
    "\n",
    "\n",
    "    # ort_sess = ort.InferenceSession(export_path, providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])\n",
    "    # outputs1 = ort_sess.run(None, {'input': dummy_input1.numpy()})\n",
    "    # outputs2 = ort_sess.run(None, {'input': dummy_input2.numpy()})\n",
    "\n",
    "    # predicted1 = model(dummy_input1)\n",
    "    # predicted2 = model(dummy_input2)\n",
    "\n",
    "    # # Print Result \n",
    "\n",
    "\n",
    "    # print(f\"Difference1: {predicted1.detach().numpy() - outputs1[0]}\")\n",
    "    # print(f\"Difference2: {predicted2.detach().numpy() - outputs2[0]}\")\n",
    "\n",
    "    # print(dummy_input1.size())\n",
    "    # print(dummy_input2.size())\n",
    "    # break\n",
    "with open(\"onnx/thresholds.json\", \"w\") as fp:\n",
    "    json.dump(thresholds, fp)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6ddece17a642146cc49b2b032ef0865aafdc2c2bbdb5ddaf5cd80c99ab7aea91"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
